{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fixing import errors of the\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# This code navigates up one directory from the notebook's location ('examples/')\n",
    "# to get the project's root directory.\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# We check if the path is already in the system path.\n",
    "# If not, we add it to the beginning of the list.\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added project root to Python path: {project_root}\")\n",
    "else:\n",
    "    print(f\"Project root is already in Python path: {project_root}\")\n",
    "\n",
    "# Optional: You can print the first few paths to verify\n",
    "print(\"\\nVerifying sys.path:\")\n",
    "for i, path in enumerate(sys.path[:5]):\n",
    "    print(f\"{i}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.core import SimpleDirectoryReader, PropertyGraphIndex,Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model= \"gemma3:12b\",\n",
    "    request_timeout=120.0,\n",
    "    context_window=8128,\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size=512\n",
    "Settings.chunk_overlap=64\n",
    "\n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"snowflake-arctic-embed2:latest\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a066c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../.data/novel.json', 'r') as file:\n",
    "    # Load the JSON data from the file into a Python object\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [\"gli\",\"llm\",\"hybrid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_knowledge_graph_data(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the total number of nodes and relations from an HTML file\n",
    "    containing a vis.js knowledge graph.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the HTML file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the counts of 'nodes' and 'relations',\n",
    "              or an error message if data cannot be extracted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": f\"File not found at {file_path}\"}\n",
    "\n",
    "    # Use regular expressions to find the nodes and edges data\n",
    "    # The re.DOTALL flag allows '.' to match newlines\n",
    "    nodes_pattern = re.search(r'nodes = new vis\\.DataSet\\((.*?)\\);', html_content, re.DOTALL)\n",
    "    edges_pattern = re.search(r'edges = new vis\\.DataSet\\((.*?)\\);', html_content, re.DOTALL)\n",
    "\n",
    "    if not nodes_pattern or not edges_pattern:\n",
    "        return {\"error\": \"Could not find nodes or edges data in the specified format.\"}\n",
    "\n",
    "    # Extract the JSON string from the matched patterns\n",
    "    nodes_json_str = nodes_pattern.group(1)\n",
    "    edges_json_str = edges_pattern.group(1)\n",
    "\n",
    "    try:\n",
    "        # Parse the JSON string into a Python list\n",
    "        nodes_data = json.loads(nodes_json_str)\n",
    "        edges_data = json.loads(edges_json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Failed to parse the data. Check if it is valid JSON.\"}\n",
    "\n",
    "    # Count the number of nodes and relations\n",
    "    num_nodes = len(nodes_data)\n",
    "    num_relations = len(edges_data)\n",
    "\n",
    "    return {\n",
    "        \"nodes\": num_nodes,\n",
    "        \"relations\": num_relations\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2634ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only needs to be executed if no graphs in .persistent_storage/.graphs/ has been created, they are essential for the extraction of nodes\n",
    "for mode in modes:\n",
    "    for novel in data:\n",
    "        corpus_name = novel[\"corpus_name\"]\n",
    "        index = load_index_from_storage(\n",
    "        StorageContext.from_defaults(persist_dir=f\"./.persistent_storage/.storage_context/{mode}/{corpus_name}\"))\n",
    "        index.property_graph_store.save_networkx_graph(name=f\"./.persistent_storage/.graphs/{mode}/{corpus_name}_kg.html\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8651465",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in modes:\n",
    "    added_nodes = 0\n",
    "    added_rels = 0\n",
    "    for novel in data:\n",
    "        corpus_name = novel[\"corpus_name\"]\n",
    "        file_path = f\"./.persistent_storage/.graphs/{mode}/{corpus_name}_kg.html\"\n",
    "        kg_data = extract_knowledge_graph_data(file_path)\n",
    "        if \"error\" in kg_data:\n",
    "            print(kg_data[\"error\"])\n",
    "        else:\n",
    "            added_nodes = added_nodes + kg_data[\"nodes\"]\n",
    "            added_rels = added_rels + kg_data[\"relations\"]\n",
    "    print(f\"Mode: {mode}\")\n",
    "    print(f\"num nodes: {added_nodes}\")\n",
    "    print(f\"num rels: {added_rels}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grag-llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
