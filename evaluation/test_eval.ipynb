{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7bc864d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root to Python path: /home/nick/projects/Llama-Index-GliREL-GraphRAG\n",
      "\n",
      "Verifying sys.path:\n",
      "0: /home/nick/projects/Llama-Index-GliREL-GraphRAG\n",
      "1: /usr/lib/python312.zip\n",
      "2: /usr/lib/python3.12\n",
      "3: /usr/lib/python3.12/lib-dynload\n",
      "4: \n"
     ]
    }
   ],
   "source": [
    "### Fixing import errors of the\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# This code navigates up one directory from the notebook's location ('examples/')\n",
    "# to get the project's root directory.\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# We check if the path is already in the system path.\n",
    "# If not, we add it to the beginning of the list.\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added project root to Python path: {project_root}\")\n",
    "else:\n",
    "    print(f\"Project root is already in Python path: {project_root}\")\n",
    "\n",
    "# Optional: You can print the first few paths to verify\n",
    "print(\"\\nVerifying sys.path:\")\n",
    "for i, path in enumerate(sys.path[:5]):\n",
    "    print(f\"{i}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fedaed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import logging\n",
    "import nest_asyncio\n",
    "import argparse\n",
    "import json\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Apply nest_asyncio for Jupyter environments\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(format=\"%(levelname)s:%(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49f503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core import Document\n",
    "from src.GlirelPathExtractor import GlirelPathExtractor \n",
    "from src.RecursivePathExtractor import RecursiveLLMPathExtractor\n",
    "from llama_index.core import SimpleDirectoryReader, PropertyGraphIndex,Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core import StorageContext, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b4bf3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../.data/novel.json', 'r') as file:\n",
    "    # Load the JSON data from the file into a Python object\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522aa375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_questions_by_source(question_list):\n",
    "    grouped_questions = {}\n",
    "\n",
    "    for question in question_list:\n",
    "        source = question.get(\"source\")\n",
    "\n",
    "        if source not in grouped_questions:\n",
    "            grouped_questions[source] = []\n",
    "\n",
    "        grouped_questions[source].append(question)\n",
    "\n",
    "    return grouped_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b164c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model= \"gemma3:12b\",\n",
    "    request_timeout=120.0,\n",
    "    context_window=8128,\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size=512\n",
    "Settings.chunk_overlap=64\n",
    "\n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"snowflake-arctic-embed2:latest\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86745897",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "---Role---\n",
    "You are a helpful assistant responding to user queries.\n",
    "\n",
    "---Goal---\n",
    "Generate direct and concise answers based strictly on the provided Knowledge Base.\n",
    "Respond in plain text without explanations or formatting.\n",
    "Maintain conversation continuity and use the same language as the query.\n",
    "If the answer is unknown, respond with \"I don't know\".\n",
    "\n",
    "---Conversation History---\n",
    "{history}\n",
    "\n",
    "---Knowledge Base---\n",
    "{context_data}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b5270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./.persistent_storage/gli/Novel-10146/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./.persistent_storage/gli/Novel-10146/index_store.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "# initalize rag\n",
    "index = load_index_from_storage(\n",
    "    StorageContext.from_defaults(persist_dir=\"./.persistent_storage/llm/Novel-10146\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0199d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"Novel-5956\",\"Novel-2544\",\"Novel-8559\",\"Novel-10146\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b67bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "        llm=llm,\n",
    "        response_mode=\"compact\",\n",
    "        similarity_top_k=8,\n",
    "        embedding_mode=\"hybrid\",\n",
    "        include_text=True,\n",
    "    \n",
    "         \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cae1799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bishop Willoughby was a well-known character of the early times. A short conversation with him would readily make patent the fact that he wasn't really a bishop. The printer-reporter mistakenly said \"Bishop Willoughby administered the rite of confirmation\" when he should have said Bishop Whipple.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='Bishop Willoughby was a well-known character of the early times. A short conversation with him would readily make patent the fact that he wasn\\'t really a bishop. The printer-reporter mistakenly said \"Bishop Willoughby administered the rite of confirmation\" when he should have said Bishop Whipple.', source_nodes=[NodeWithScore(node=TextNode(id_='5a674c9b-1160-48f7-bbe9-3899f82b3f5a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='Novel-10146', node_type='4', metadata={}, hash='9ef9061939b8ffac1d8a9134eb0d7900d028a856f8170090f4e406fea3fcc7db'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f79b9a8d-99e5-4eef-a94e-ace126f910aa', node_type='1', metadata={}, hash='8a242eea6eee6f205a3bd6fe4b8bdf552b4a1056c12c2f91c01be3c097a98a28'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='78267074-b83b-4375-bc91-74a5c6a87e6c', node_type='1', metadata={}, hash='fe1e484f8804aeb00c3df44bb938d61bd0a2529583c1de26eb1decd03ba1ae01')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Here are some facts extracted from the provided text:\\n\\nWabasha -> parent_of -> his father\\n\\nAt this fire a large number of frame buildings on the opposite side of the street were destroyed. When the Cosmopolitan hotel burned the walls of the old building were left standing, and although they were pronounced dangerous by the city authorities, had not been demolished. Dr. Schell, one of the best known physicians of the city, occupied a little frame building near the hotel, and he severely denounced the city authorities for their lax enforcement of the law. One night at 10 o'clock the city was visited by a terrific windstorm, and suddenly a loud crash was heard in the vicinity of the doctor's office. A portion of the walls of the hotel had fallen and the little building occupied by the doctor had been crushed in. The fire alarm was turned on and the fire laddies were soon on the spot. No one supposed the doctor was alive, but after the firemen had been at work a short time they could hear the voice of the doctor from underneath the rubbish. In very vigorous English, which the doctor knew so well how to use, he roundly upbraided the fire department for not being more expeditious in extricating him from his perilous position. After the doctor had been taken out of the ruins It was found that he had not been seriously injured, and in the course of a few weeks was able to resume practice. During the winter of 1868 the Emmert house, situated on Bench street near Wabasha, was destroyed by fire. The Emmert house was built in territorial times by Fred Emmert, who for some time kept a hotel and boarding house at that place. It had not been used for hotel purposes for some time, but was occupied by a  family and used as a boarding-house for <DW52> people. While the flames were rapidly consuming the old building the discovery was made that a man and his wife were sick in one of the rooms with smallpox. The crowd of onlookers fled in terror, and they would have been burned alive had not two courageous firemen carried them out of the building. It was an unusually cold night and the <DW52> people were dumped into the middle of the street and there allowed to remain. They were provided with clothing and some of the more venturesome even built a fire for them, but no one would volunteer to take them to a place of shelter.\", mimetype='text/plain', start_char_idx=110694, end_char_idx=112946, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3713213558181874), NodeWithScore(node=TextNode(id_='3b11de06-56b3-4ea4-89aa-7125966d3b78', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='Novel-10146', node_type='4', metadata={}, hash='9ef9061939b8ffac1d8a9134eb0d7900d028a856f8170090f4e406fea3fcc7db'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='55f72a14-b642-4342-97c1-53f2d0e2c3b0', node_type='1', metadata={}, hash='b694081d40ac434e0a7952779508a4053932da6426dab9060691359f334abdc5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='462914cc-e2ad-42f8-82bd-d66b7ec5a0fe', node_type='1', metadata={}, hash='e858f721f7caeff315fac9cb0799c8ea3aa392196fed3a11f65a7abfb0bc458d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Here are some facts extracted from the provided text:\\n\\nhis father -> child_of -> Little Crow\\nhis father -> lives_in -> St. Paul\\nhis father -> parent_of -> I\\nhis father -> parent_of -> your daughter\\nMy wife -> parent_of -> his father\\nRattling Runner -> parent_of -> his father\\nDakotah -> parent_of -> his father\\nhis father -> died_in -> Hutchinson\\nhis father -> child_of -> my children\\nyour daughter -> parent_of -> his father\\nmy children -> child_of -> his father\\nhis father -> parent_of -> My wife\\nhis father -> parent_of -> Wabasha\\nhis father -> born_in -> Kaposia\\n\\nRattling Runner, who was a son-in-law of Wabasha, dictated the following letter, which is a sample of the confessions made to Dr. Riggs: \"Wabasha, you have deceived me. You told me if we followed the advice of Gen. Sibley and gave ourselves up, all would be well--no innocent man would be injured. I have not killed or injured a white man or any white person. I have not participated in the plunder of their property; and yet to-day I am set apart for execution and must die, while men who are guilty will remain in prison. My wife is your daughter, my children are your grandchildren. I leave them all in your care and under your protection. Do not let them suffer, and when they are grown up let them know that their father died because he followed the advice of his chief, and without having the blood of a white man to answer for to the Holy Spirit. My wife and children are dear to me. Let them not grieve for me; let them remember that the brave should be prepared to meet death, and I will do as becomes a Dakotah.\" Wabasha was a Sioux chief, and although he was not found guilty of participating in any of the massacres of women and children, he was probably in all the most important battles. Wabasha county, and Wabasha street in St. Paul were named after his father. After the execution the bodies were taken down, loaded into wagons and carried down to a sandbar in front of the city, where they were all dumped into the same hole. They did not remain there long, but were spirited away by students and others familiar with the use of a dissecting knife. Little Crow, the chief instigator of the insurrection was not with the number that surrendered, but escaped and was afterward killed by a farmer named Lamson, in the vicinity of Hutchinson. His scalp is now in the state historical society. Little Crow was born in Kaposia, a few miles below St. Paul, and was always known as a bad Indian.', mimetype='text/plain', start_char_idx=76751, end_char_idx=78656, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3713213558181874), NodeWithScore(node=TextNode(id_='41fe1e23-c6e7-416a-bb2f-17234e3ec460', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='Novel-10146', node_type='4', metadata={}, hash='9ef9061939b8ffac1d8a9134eb0d7900d028a856f8170090f4e406fea3fcc7db'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aa9d33da-117f-40b6-b871-ae70303904ae', node_type='1', metadata={}, hash='efe7fb72dddf2379d3bd97cff21b69f17375fb2986428addf12bbbb0852c0cbc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='51b63a27-c9ef-47c3-98b4-e8f606061daf', node_type='1', metadata={}, hash='186f4301a95a88325877e857cb002065aa93b1b503091c3461fdbfc09ffd93c8')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Here are some facts extracted from the provided text:\\n\\nI -> parent_of -> his father\\n\\n\"Next!\" \"Next!\" \"Next!\" said the school-master, and my pulse beat faster and faster as the older scholars ahead of me were relegated to their seats. At last the crucial time had come. I was the only one left standing. As the school-master stood directly in front of me and said \"Next,\" I could see by the twinkle in his eye that he thought I could correctly spell the word. My countenance had betrayed me. With a clear and distinct voice loud enough to be heard by every one in the room I spelled out \"ph-th-is-ic--phthisic.\" \"Correct,\" said the school-master, and all the scholars looked aghast at my promptness. I shall never forget the kindly smile of the old school-master, as he laid the spelling book upon the teacher\\'s desk, with the quiet remark: \"I told you he could spell.\" I had spelled down four schools, and my reputation as a speller was established. Our school was declared to have furnished the champion speller of the four districts, and ever after my name was not the last one to be called. On my return home I was not compelled to ride under the driver\\'s seat. HALF A CENTURY WITH THE PIONEER PRESS. Pioneer Press, April 18, 1908:--Frank Moore, superintendent of the composing room if the Pioneer Press, celebrated yesterday the fiftieth anniversary of his connection with the paper. A dozen of the old employes of the Pioneer Press entertained Mr. Moore at an informal dinner at Magee\\'s to celebrate the unusual event. Mr. Moore\\'s service on the Pioneer Press, in fact, has been longer than the Pioneer Press itself, for he began his work on one of the newspapers which eventually was merged into the present Pioneer Press. He has held his present position as the head of the composing room for about forty years. Frank Moore was fifteen years old when he came to St. Paul from Tioga county, Pa., where he was born. He came with his brother, George W. Moore, who was one of the owners and managers of the Minnesotian. His brother had been East and brought the boy West with him. Mr. Moore\\'s first view of newspaper work was on the trip up the river to St. Paul.', mimetype='text/plain', start_char_idx=240217, end_char_idx=242298, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3713213558181874), NodeWithScore(node=TextNode(id_='48b44f67-e40c-4aad-89e4-b8da19be49bd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='Novel-10146', node_type='4', metadata={}, hash='9ef9061939b8ffac1d8a9134eb0d7900d028a856f8170090f4e406fea3fcc7db'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cd7c89b5-8d01-4f0b-b23d-778f63366932', node_type='1', metadata={}, hash='aa6d8c29d65c1ce5e8c4e95ff8a3c54c312d69cea1636b8909ed155f7262a2d4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bae61cac-95d8-4ab5-ba39-db400785e1a2', node_type='1', metadata={}, hash='f5ff69562ed13e78c7345a05e944d0c7685f841e51406bdd156e5888bbaacfd6')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Here are some facts extracted from the provided text:\\n\\nBishop Willoughby -> employee_of -> Times\\nBishop Willoughby -> employee_of -> the Minnesotian\\n\\nThe next day the Times had a long account of his misfortune, and at the conclusion of his article he hurled the pope\\'s bull of excommunication at the miscreant. It was a fatal bull and was Mr. Jebb\\'s reportorial finish. A fresh graduate from the case at one time wrote a scurrilous biography of Washington. The editor of the paper on which he was employed was compelled to make editorial apology for its unfortunate appearance. To make the matter more offensive the author on several different occasions reproduced the article and credited its authorship to the editor who was compelled to apologize for it. In two different articles on nationalities by two different young printer reporters, one referred to the Germans as \"the beer-guzzling Dutch,\" and the other, speaking of the English said \"thank the Lord we have but few of them in our midst,\" caused the writers to be promptly relegated back to the case. Bishop Willoughby was a well-known character of the early times. A short conversation with him would readily make patent the fact that he wasn\\'t really a bishop. In an account of confirming a number of people at Christ church a very conscientious printer-reporter said \"Bishop Willoughby administered the rite of confirmation,\" when he should have said Bishop Whipple. He was so mortified at his unfortunate blunder that he at once tendered his resignation. Of course it was not accepted. Editors and printers of territorial times were more closely affiliated than they are to-day. Meager hotel accommodations and necessity for economical habits compelled many of them to work and sleep in the same room. All the offices contained blankets and cots, and as morning newspapers were only morning newspapers in name, the tired and weary printer could sleep the sleep of the just without fear of disturbance. Nearly all the early editors were also printers. Earle S. Goodrich, editor-in-chief of the Pioneer: Thomas Foster, editor of the Minnesotian; T.M. Newson, editor of the Times, and John P. Owens, first editor of the Minnesotian, were all printers. When the old Press removed from Bridge Square in 1869 to the new building on the corner of Third and Minnesota streets, Earle S. Goodrich came up into the composing room and requested the privilege of setting the first type in the new building.', mimetype='text/plain', start_char_idx=178733, end_char_idx=181041, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.36592620219015815), NodeWithScore(node=TextNode(id_='93153d11-4360-4c31-ad1a-d2e06766f535', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='Novel-10146', node_type='4', metadata={}, hash='9ef9061939b8ffac1d8a9134eb0d7900d028a856f8170090f4e406fea3fcc7db'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1410e499-f94e-4e06-ba6e-e2c675df3ea1', node_type='1', metadata={}, hash='e73d4a22b9e8c44da713098195994f3d539c2c75410b033bbdfdf3b3222f9ec3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='99b0bc6b-f977-4692-944b-248cd893c2d7', node_type='1', metadata={}, hash='f96571fb9e6696a3ca4e5cd85fe42c449f1d6aa97de24447bc91b228c4da48f2')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Here are some facts extracted from the provided text:\\n\\nFather Abraham -> member_of -> The Press\\nFather Abraham -> member_of -> Times\\nFather Abraham -> member_of -> the Press\\nFather Abraham -> member_of -> Union force\\nFather Abraham -> lives_in -> East Minneapolis\\nFather Abraham -> member_of -> St. Anthony Falls News\\nFather Abraham -> member_of -> Press\\nFather Abraham -> member_of -> Printers\\n\\nHe smiled, but did not speak. As soon as I learned what had happened I did not do either. The best of the joke was, the Times could not obtain an early copy of the Pioneer and set up the bogus news from the Minnesotian, and had their edition printed and ready to circulate when they heard of the sell. They at once set up the genuine news and circulated both the bogus and regular, and made fun of the Minnesotian for being so easily taken in. The Pioneer retained the monopoly of the news until the Press was started, on the 1st of January, 1861. The Press made arrangements with Mr. Winslow for full telegraphic dispatches, but there was another hitch in the spring of 1861 and for some time the Press had to obtain its telegraph from proof sheets of the St. Anthony Falls News, a paper published in what is now East Minneapolis. Gov. Marshall was very much exercised at being compelled to go to a neighboring town for telegraph news, and one night when news of unusual importance was expected he had a very stormy interview with Mr. Winslow. No one ever knew exactly what he told him, but that night the Press had full telegraphic reports, and has had ever since. Gov. Marshall was a noble man. When the first battle of Bull Run occurred the earlier reports announced a great Union victory. I remember of going to Dan Rice\\'s circus that night and felt as chipper as a young kitten. After the circus was out I went back to the office to see if any late news had been received. I met Gov. Marshall at the door, and with tears rolling down his cheeks he informed me that the Union force had met with a great reverse and he was afraid the country would never recover from it. But it did, and the governor was afterward one of the bravest of the brave in battling for his country\\'s honor. Printers were very patriotic, and when Father Abraham called for \"three hundred thousand more\" in July, 1862, so many enlisted that it was with much difficulty that the paper was enabled to present a respectable appearance. The Press advertised for anything that could set type to come in and help it out. I remember one man applying who said he never had set any type, but he had a good theoretical knowledge of the business.', mimetype='text/plain', start_char_idx=16545, end_char_idx=18758, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.33371344199318903), NodeWithScore(node=TextNode(id_='fa367b0f-b221-41fd-a933-7fa60d7d334b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='Novel-10146', node_type='4', metadata={}, hash='9ef9061939b8ffac1d8a9134eb0d7900d028a856f8170090f4e406fea3fcc7db'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e45f58c7-ee27-4f41-9344-06b014c3f958', node_type='1', metadata={}, hash='79c4132754edc8ae7b01d52ec384815a4e3538ce9df75dca3b1e3a4c9d12a28b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3a5fb096-6e44-4409-b42c-896e8ba45d6a', node_type='1', metadata={}, hash='805ff8976ebf074387fb91e5169d33514f94cfe20f4ea8c297f6661cf7ce380a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Here are some facts extracted from the provided text:\\n\\nthe pastor -> died_in -> little edifice\\nthe pastor -> member_of -> House of Hope\\n\\nPresident Lincoln was his ideal statesman. The members of the House of Hope were intensely patriotic. Many of their number were at the front defending their imperiled country. Scores and scores of times during the desperate conflict had the eloquent pastor of this church delivered stirring addresses favoring a vigorous prosecution of the war. During the darkest days of the Rebellion, when the prospect of the final triumph of the cause of the Union seemed furthest off, Mr. Noble never faltered; he believed that the cause was just and that right would finally triumph. When the terrible and heart-rending news was received that an assassin\\'s bullet had ended the life of the greatest of all presidents the effect was so paralyzing that hearts almost ceased beating. Every member of the congregation felt as if one of their own household had been suddenly taken from them. The services at the church on the Sunday morning following the assassination were most solemn and impressive. The little edifice was crowded almost to suffication, and when the pastor was seen slowly ascending the pulpit, breathless silence prevailed. He was pale and haggard, and appeared to be suffering great mental agony. With bowed head and uplifted hands, and with a voice trembling with almost uncontrollable emotion, he delivered one of the most fervent and impressive invocations ever heard by the audience. Had the dead body of the president been placed in front of the altar, the solemnity of the occasion could not have been greater. In the discourse that followed, Mr. Noble briefly sketched the early history of the president, and then devoted some time to the many grand deeds he had accomplished during the time he had been in the presidential chair. For more than four years he had patiently and anxiously watched the progress of the terrible struggle, and now, when victory was in sight, when it was apparent to all that the fall of Richmond, the surrender of Lee and the probable surrender of Johnston would end the long war, he was cruelly stricken down by the hand of an assassin. \"With malice towards none and with charity to all, and with firmness for the right, as God gives us to see the right,\" were utterances then fresh from the president\\'s lips. To strike down such a man at such a time was indeed a crime most horrible. There was scarcely a dry eye in the audience. Men and women alike wept.', mimetype='text/plain', start_char_idx=227429, end_char_idx=229826, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.32308373340846797), NodeWithScore(node=TextNode(id_='714e4f19-b253-45de-836b-5b4221866a53', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='Novel-10146', node_type='4', metadata={}, hash='9ef9061939b8ffac1d8a9134eb0d7900d028a856f8170090f4e406fea3fcc7db'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d68facf6-262c-4cac-876c-98588ca1a722', node_type='1', metadata={}, hash='0965085ae455fa6b6ab919b34bee2c0bca2940965cdab8a13ab2f63c437c5cb1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5dd44f80-ee8b-4e3b-917e-5833f39bec55', node_type='1', metadata={}, hash='40bc911f3b3e14785837949ad212832086dd0a6d89de73f1090c292d4df50d83')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Here are some facts extracted from the provided text:\\n\\nChippewa chief -> lives_in -> Minnesota\\n\\nThe other Indians did not like this, and became envious of them because they discontinued the customs of the tribe. There was even said to have been a secret organization among the tepee Indians whose object it was to declare war upon the whites. The Indians also claimed that they were not fairly dealt with by the traders; that they had to rely entirely upon their word for their indebtedness to them; that they were ignorant of any method of keeping accounts, and that when the paymaster came the traders generally took all that was coming, and often leaving many of them in debt. They protested against permitting the traders to sit at the pay table of the government paymaster and deduct from their small annuities the amount due them. They had at least one white man's idea--they wanted to pay their debts when they got ready. For several weeks previous to the outbreak the Indians came to the agencies to get their money. Day after day and week after week passed and there was no sign of paymasters. The year 1862 was the the second year of the great Rebellion, and as the government officers had been taxed to their utmost to provide funds for the prosecution of the war, it looked as though they had neglected their wards in Minnesota. Many of the Indians who had gathered about the agencies were out of money and their families were suffering. The Indians were told that on account of the great war in which the government was engaged the payment would never be made. Their annuities were payable in gold and they were told that the great father had no gold to pay them with. Maj. Galbraith, the agent of the Sioux, had organized a company to go South, composed mostly of half-breeds, and this led the Indians to believe that now would be the time to go to war with the whites and get their land back. It was believed that the men who had enlisted last had all left the state and that before, help could be sent they could clear the country of the whites, and that the Winnebagos and Chippewas would come to their assistance. It is known that the Sioux had been in communication with Hole-in-the-Day, the Chippewa chief, but the outbreak was probably precipitated before they came to an understanding. It was even said at the time that the Confederate government had emissaries among them, but the Indians deny this report and no evidence has ever been collected proving its truthfulness.\", mimetype='text/plain', start_char_idx=55820, end_char_idx=58218, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.308033826426062)], metadata={'5a674c9b-1160-48f7-bbe9-3899f82b3f5a': {}, '3b11de06-56b3-4ea4-89aa-7125966d3b78': {}, '41fe1e23-c6e7-416a-bb2f-17234e3ec460': {}, '48b44f67-e40c-4aad-89e4-b8da19be49bd': {}, '93153d11-4360-4c31-ad1a-d2e06766f535': {}, 'fa367b0f-b221-41fd-a933-7fa60d7d334b': {}, '714e4f19-b253-45de-836b-5b4221866a53': {}})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await query_engine.aquery(\"In the narrative surrounding Ellen, what is the relationship between her father and the bishop, as indicated by their roles in the story?\")\n",
    "print(response.response)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d133d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.property_graph import (\n",
    "    PGRetriever,\n",
    "    VectorContextRetriever,\n",
    "    LLMSynonymRetriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31e67f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_retrievers = [\n",
    "    VectorContextRetriever(index.property_graph_store),\n",
    "    LLMSynonymRetriever(index.property_graph_store),\n",
    "]\n",
    "\n",
    "retriever = index.as_retriever(path_depth=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b54ff917",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "        llm=llm,\n",
    "        response_mode=\"compact\",\n",
    "        similarity_top_k=8,\n",
    "        embedding_mode=\"hybrid\",\n",
    "        include_text=True,\n",
    "    \n",
    "         \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e455ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(query_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine  = RetrieverQueryEngine.from_args(\n",
    "   retriever=retriever, llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(query_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183bdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Van Bibber_READ_of the fight between \\\\ Dutchy\\\\  Mack and the \\\\ Black Diamond\\\\ '",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#nest_asyncio.apply()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m query_engine.aquery(\u001b[33m\"\u001b[39m\u001b[33mIn the narrative surrounding Ellen, what is the relationship between her father and the bishop, as indicated by their roles in the story?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.response)\n\u001b[32m      4\u001b[39m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:369\u001b[39m, in \u001b[36mDispatcher.span.<locals>.async_wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    362\u001b[39m     id_=id_,\n\u001b[32m    363\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     tags=tags,\n\u001b[32m    367\u001b[39m )\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    371\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/base/base_query_engine.py:64\u001b[39m, in \u001b[36mBaseQueryEngine.aquery\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     63\u001b[39m         str_or_query_bundle = QueryBundle(str_or_query_bundle)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     query_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aquery(str_or_query_bundle)\n\u001b[32m     65\u001b[39m dispatcher.event(\n\u001b[32m     66\u001b[39m     QueryEndEvent(query=str_or_query_bundle, response=query_result)\n\u001b[32m     67\u001b[39m )\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:369\u001b[39m, in \u001b[36mDispatcher.span.<locals>.async_wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    362\u001b[39m     id_=id_,\n\u001b[32m    363\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     tags=tags,\n\u001b[32m    367\u001b[39m )\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    371\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/query_engine/retriever_query_engine.py:197\u001b[39m, in \u001b[36mRetrieverQueryEngine._aquery\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    195\u001b[39m     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\n\u001b[32m    196\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     nodes = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aretrieve(query_bundle)\n\u001b[32m    199\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_synthesizer.asynthesize(\n\u001b[32m    200\u001b[39m         query=query_bundle,\n\u001b[32m    201\u001b[39m         nodes=nodes,\n\u001b[32m    202\u001b[39m     )\n\u001b[32m    204\u001b[39m     query_event.on_end(payload={EventPayload.RESPONSE: response})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/query_engine/retriever_query_engine.py:141\u001b[39m, in \u001b[36mRetrieverQueryEngine.aretrieve\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) -> List[NodeWithScore]:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     nodes = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retriever.aretrieve(query_bundle)\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._apply_node_postprocessors(nodes, query_bundle=query_bundle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:369\u001b[39m, in \u001b[36mDispatcher.span.<locals>.async_wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    362\u001b[39m     id_=id_,\n\u001b[32m    363\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     tags=tags,\n\u001b[32m    367\u001b[39m )\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    371\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/base/base_retriever.py:277\u001b[39m, in \u001b[36mBaseRetriever.aretrieve\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.as_trace(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    274\u001b[39m         CBEventType.RETRIEVE,\n\u001b[32m    275\u001b[39m         payload={EventPayload.QUERY_STR: query_bundle.query_str},\n\u001b[32m    276\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         nodes = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aretrieve(query_bundle=query_bundle)\n\u001b[32m    278\u001b[39m         nodes = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ahandle_recursive_retrieval(\n\u001b[32m    279\u001b[39m             query_bundle=query_bundle, nodes=nodes\n\u001b[32m    280\u001b[39m         )\n\u001b[32m    281\u001b[39m         retrieve_event.on_end(\n\u001b[32m    282\u001b[39m             payload={EventPayload.NODES: nodes},\n\u001b[32m    283\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/indices/property_graph/retriever.py:66\u001b[39m, in \u001b[36mPGRetriever._aretrieve\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sub_retriever \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sub_retrievers:\n\u001b[32m     64\u001b[39m     tasks.append(sub_retriever.aretrieve(query_bundle))\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m async_results = \u001b[38;5;28;01mawait\u001b[39;00m run_jobs(\n\u001b[32m     67\u001b[39m     tasks, workers=\u001b[38;5;28mself\u001b[39m.num_workers, show_progress=\u001b[38;5;28mself\u001b[39m.show_progress\n\u001b[32m     68\u001b[39m )\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# flatten the results\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._deduplicate([node \u001b[38;5;28;01mfor\u001b[39;00m nodes \u001b[38;5;129;01min\u001b[39;00m async_results \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:369\u001b[39m, in \u001b[36mDispatcher.span.<locals>.async_wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    362\u001b[39m     id_=id_,\n\u001b[32m    363\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     tags=tags,\n\u001b[32m    367\u001b[39m )\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    371\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/async_utils.py:169\u001b[39m, in \u001b[36mrun_jobs\u001b[39m\u001b[34m(jobs, show_progress, workers, desc)\u001b[39m\n\u001b[32m    167\u001b[39m     results = \u001b[38;5;28;01mawait\u001b[39;00m tqdm_asyncio.gather(*pool_jobs, desc=desc)\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*pool_jobs)\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:369\u001b[39m, in \u001b[36mDispatcher.span.<locals>.async_wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    362\u001b[39m     id_=id_,\n\u001b[32m    363\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     tags=tags,\n\u001b[32m    367\u001b[39m )\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    371\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/async_utils.py:160\u001b[39m, in \u001b[36mrun_jobs.<locals>.worker\u001b[39m\u001b[34m(job)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;129m@dispatcher\u001b[39m.span\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mworker\u001b[39m(job: Coroutine) -> Any:\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m job\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:369\u001b[39m, in \u001b[36mDispatcher.span.<locals>.async_wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    362\u001b[39m     id_=id_,\n\u001b[32m    363\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     tags=tags,\n\u001b[32m    367\u001b[39m )\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    371\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/base/base_retriever.py:277\u001b[39m, in \u001b[36mBaseRetriever.aretrieve\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.as_trace(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    274\u001b[39m         CBEventType.RETRIEVE,\n\u001b[32m    275\u001b[39m         payload={EventPayload.QUERY_STR: query_bundle.query_str},\n\u001b[32m    276\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         nodes = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aretrieve(query_bundle=query_bundle)\n\u001b[32m    278\u001b[39m         nodes = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ahandle_recursive_retrieval(\n\u001b[32m    279\u001b[39m             query_bundle=query_bundle, nodes=nodes\n\u001b[32m    280\u001b[39m         )\n\u001b[32m    281\u001b[39m         retrieve_event.on_end(\n\u001b[32m    282\u001b[39m             payload={EventPayload.NODES: nodes},\n\u001b[32m    283\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/indices/property_graph/sub_retrievers/base.py:150\u001b[39m, in \u001b[36mBasePGRetriever._aretrieve\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_aretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) -> List[NodeWithScore]:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     nodes = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aretrieve_from_graph(query_bundle)\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.include_text \u001b[38;5;129;01mand\u001b[39;00m nodes:\n\u001b[32m    152\u001b[39m         nodes = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_add_source_text(nodes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:369\u001b[39m, in \u001b[36mDispatcher.span.<locals>.async_wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    362\u001b[39m     id_=id_,\n\u001b[32m    363\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     tags=tags,\n\u001b[32m    367\u001b[39m )\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    371\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/indices/property_graph/sub_retrievers/vector.py:230\u001b[39m, in \u001b[36mVectorContextRetriever.aretrieve_from_graph\u001b[39m\u001b[34m(self, query_bundle, limit)\u001b[39m\n\u001b[32m    228\u001b[39m         scores = query_result.similarities\n\u001b[32m    229\u001b[39m         kg_nodes = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._graph_store.aget(ids=kg_ids)\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m         triplets = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._graph_store.aget_rel_map(\n\u001b[32m    231\u001b[39m             kg_nodes,\n\u001b[32m    232\u001b[39m             depth=\u001b[38;5;28mself\u001b[39m._path_depth,\n\u001b[32m    233\u001b[39m             limit=limit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._limit,\n\u001b[32m    234\u001b[39m             ignore_rels=[KG_SOURCE_REL],\n\u001b[32m    235\u001b[39m         )\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m triplet \u001b[38;5;129;01min\u001b[39;00m triplets:\n\u001b[32m    238\u001b[39m     score1 = (\n\u001b[32m    239\u001b[39m         scores[kg_ids.index(triplet[\u001b[32m0\u001b[39m].id)] \u001b[38;5;28;01mif\u001b[39;00m triplet[\u001b[32m0\u001b[39m].id \u001b[38;5;129;01min\u001b[39;00m kg_ids \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n\u001b[32m    240\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/graph_stores/types.py:468\u001b[39m, in \u001b[36mPropertyGraphStore.aget_rel_map\u001b[39m\u001b[34m(self, graph_nodes, depth, limit, ignore_rels)\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maget_rel_map\u001b[39m(\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    462\u001b[39m     graph_nodes: List[LabelledNode],\n\u001b[32m   (...)\u001b[39m\u001b[32m    465\u001b[39m     ignore_rels: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    466\u001b[39m ) -> List[Triplet]:\n\u001b[32m    467\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Asynchronously get depth-aware rel map.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_rel_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_rels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/graph_stores/simple_labelled.py:114\u001b[39m, in \u001b[36mSimplePropertyGraphStore.get_rel_map\u001b[39m\u001b[34m(self, graph_nodes, depth, limit, ignore_rels)\u001b[39m\n\u001b[32m    111\u001b[39m triplets = []\n\u001b[32m    113\u001b[39m cur_depth = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m graph_triplets = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_triplets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph_nodes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m seen_triplets = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(graph_triplets) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cur_depth < depth:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/graph_stores/simple_labelled.py:72\u001b[39m, in \u001b[36mSimplePropertyGraphStore.get_triplets\u001b[39m\u001b[34m(self, entity_names, relation_names, properties, ids)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ids \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m properties \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m entity_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m relation_names:\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m triplets = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_triplets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m entity_names:\n\u001b[32m     74\u001b[39m     triplets = [\n\u001b[32m     75\u001b[39m         t\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m triplets\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m t[\u001b[32m0\u001b[39m].id \u001b[38;5;129;01min\u001b[39;00m entity_names \u001b[38;5;129;01mor\u001b[39;00m t[\u001b[32m2\u001b[39m].id \u001b[38;5;129;01min\u001b[39;00m entity_names\n\u001b[32m     78\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/grag-llama/lib/python3.12/site-packages/llama_index/core/graph_stores/types.py:153\u001b[39m, in \u001b[36mLabelledPropertyGraph.get_triplets\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_triplets\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Triplet]:\n\u001b[32m    149\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get all triplets.\"\"\"\u001b[39;00m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    151\u001b[39m         (\n\u001b[32m    152\u001b[39m             \u001b[38;5;28mself\u001b[39m.nodes[subj],\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrelations\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relation_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubj_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m    156\u001b[39m             \u001b[38;5;28mself\u001b[39m.nodes[obj],\n\u001b[32m    157\u001b[39m         )\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m subj, rel, obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.triplets\n\u001b[32m    159\u001b[39m     ]\n",
      "\u001b[31mKeyError\u001b[39m: 'Van Bibber_READ_of the fight between \\\\ Dutchy\\\\  Mack and the \\\\ Black Diamond\\\\ '"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "#nest_asyncio.apply()\n",
    "response = await query_engine.aquery(\"In the narrative surrounding Ellen, what is the relationship between her father and the bishop, as indicated by their roles in the story?\")\n",
    "print(response.response)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536fe574",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c88885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.get_formatted_sources(10000))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grag-llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
